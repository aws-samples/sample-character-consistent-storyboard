{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9e00cd-3e08-460f-905d-ece622b02369",
   "metadata": {},
   "source": [
    "## Nova Canvas Fine-Tuning for Character Consistency\n",
    "\n",
    "This notebook demonstrates how to fine-tune Amazon Nova Canvas to create character-consistent storyboards using images from the animated short film \\\"Picchu\\\".\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we'll walk through the process of fine-tuning Amazon Nova Canvas to maintain visual consistency for specific characters (Mayu and her mom) across multiple generated images. This approach allows for more precise control over character appearance than prompt engineering alone.\n",
    "\n",
    "### Prerequisites\n",
    "- AWS account with access to Amazon Bedrock\n",
    "- Appropriate IAM permissions for Bedrock, S3, and related services\n",
    "- This notebook must be run in the `us-east-1` AWS region\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>INFO:</b> At the time of development, Amazon Nova Canvas model is only available in `us-east-1`\n",
    "</div>\n",
    "\n",
    "### What You'll Learn\n",
    "- How to prepare training data from existing character images\n",
    "- How to configure and run a fine-tuning job on Amazon Nova Canvas\n",
    "- How to generate character-consistent storyboard frames with your fine-tuned model\n",
    "\n",
    "You can watch the original \\\"Picchu\\\" animated short film here: [Picchu on YouTube](https://www.youtube.com/watch?v=XfyJbkRV_Eo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19299fb3-b4de-42ed-bd32-91343d8bda35",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's install the required dependencies for this notebook. These packages will help us with image processing, AWS interactions, and visualization.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102108c-fda0-408c-ad90-204f354193b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea8b04-2042-4590-b25a-53682f530f53",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "\n",
    "Now we'll set up our AWS environment by initializing the necessary clients and defining key variables. This includes:\n",
    "- Setting up boto3 clients for Bedrock, S3, IAM, and STS\n",
    "- Defining our S3 bucket and prefix for storing training data\n",
    "- Setting the base model ID for fine-tuning\n",
    "- Creating a directory for our training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba58e94-1fc4-40c5-bf1e-80270f883929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "import time\n",
    "import json\n",
    "from image_processing import process_folders, upload_to_s3\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "region = \"us-east-1\"\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "if sess.default_bucket(): \n",
    "    bucket = sess.default_bucket()\n",
    "else:\n",
    "    bucket = \"XXXXXXXXXXXXX\" # Use your own\n",
    "\n",
    "prefix = \"picchu-canvas/images\"\n",
    "\n",
    "\n",
    "# Initialize Boto3 Clients\n",
    "bedrock = boto_session.client('bedrock')\n",
    "bedrock_runtime = boto_session.client('bedrock-runtime')\n",
    "s3 = boto_session.client('s3')\n",
    "iam_client = boto_session.client('iam')\n",
    "sts_client = boto_session.client('sts')\n",
    "\n",
    "# Account and region info\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "# Base model id for fine-tuning\n",
    "model_id = 'amazon.nova-canvas-v1:0'\n",
    "\n",
    "image_dir = \"picchu_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a31da6-6005-4144-b5a7-09715d7af103",
   "metadata": {},
   "source": [
    "### Prepare Local Directory\n",
    "\n",
    "We'll create a clean directory to store our training images. If the directory already exists, we'll remove it and create a fresh one to avoid any conflicts with previous files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a31da6-6005-4144-b5a7-09715d7af104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_replace_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)  # Remove the existing folder and its contents\n",
    "    os.makedirs(folder_path)         # Create a new, empty folder\n",
    "\n",
    "create_or_replace_folder(image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73913c20-a6a9-438d-980b-aae423413e5f",
   "metadata": {},
   "source": [
    "## Download images\n",
    "\n",
    "In this step, we'll download a pre-prepared set of images from the \\\"Picchu\\\" animated short film. These images will serve as our training data for fine-tuning the Nova Canvas model to consistently generate the main character Mayu and her mom.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c58b1c-c82b-4089-bf0f-f93124030aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/3c3519c9-93dc-404d-87f7-4d9bde05f265/picchu_images.zip\n",
    "\n",
    "!unzip picchu_images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f2681-aa0e-4b9c-8d20-3f973d6c90f1",
   "metadata": {},
   "source": [
    "### Prepare the images for fine tuning\n",
    "\n",
    "Now we'll process the downloaded images and prepare them for fine-tuning. This function will:\n",
    "1. Upload the images to our S3 bucket\n",
    "2. Generate a manifest file that pairs each image with a descriptive caption\n",
    "3. The manifest file follows the required format for Amazon Nova Canvas fine-tuning\n",
    "\n",
    "For more information on manifest file requirements, see the [Amazon Bedrock documentation on fine-tuning](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a5e237-44a0-47e5-936d-8595ab3bdfb4",
   "metadata": {},
   "source": [
    "### Process the downloaded images\n",
    "\n",
    "Now we'll process the images from the downloaded zip file. The `process_folders` function will:\n",
    "1. Extract images from the specified directories\n",
    "2. Generate appropriate captions for each image\n",
    "3. Upload the images to S3 and prepare the data structure for our manifest file\n",
    "\n",
    "This step is crucial for preparing our training data in the format required by Amazon Nova Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e72237-44a0-47e5-936d-8595ab3bdfb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updated_data = process_folders([image_dir], bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee483e6-e5e2-4bcd-b9df-224c7790b28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file = f'{prefix.split('-')[0]}_manifest.jsonl'\n",
    "with open(output_file, 'w') as f:\n",
    "    for item in updated_data:\n",
    "        item_filtered = {d:item[d] for d in item if d != 'id'}\n",
    "        f.write(json.dumps(item_filtered) + '\\n')\n",
    "print(f\"{output_file} processed completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1a2f5-bd0a-4e28-b15d-895a35e925c6",
   "metadata": {},
   "source": [
    "### Preview the manifest file\n",
    "\n",
    "Let's examine the first few entries of our manifest file to understand its structure. Each line contains a JSON object with:\n",
    "- `image-ref`: The S3 path to the image\n",
    "- `caption`: A detailed description of the image that helps the model learn the character's appearance and style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdf628-e8cb-4d19-b6f6-1fd06ef17f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 {output_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308de78-396d-46d9-a409-d72ef1b322f3",
   "metadata": {},
   "source": [
    "### Upload manifest to S3\n",
    "\n",
    "Now we'll upload our manifest file to S3. This file will be used by the fine-tuning job to locate and process our training images along with their captions.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a69b73-c636-471d-865b-768a1cf90072",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = upload_to_s3(output_file, bucket, prefix.replace(\"images\", \"manifests\"))\n",
    "training_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b4130-f651-46de-a948-91b94e209447",
   "metadata": {},
   "source": [
    "## Train Custom Model Using Bedrock\n",
    "\n",
    "Now we'll begin the process of fine-tuning the Amazon Nova Canvas model using our prepared training data. This involves several steps:\n",
    "1. Creating the necessary IAM roles and policies\n",
    "2. Configuring the fine-tuning job parameters\n",
    "3. Submitting the job to Amazon Bedrock\n",
    "4. Monitoring the job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d704e-562c-4bfd-a7e9-752a2ab34d5d",
   "metadata": {},
   "source": [
    "### Fine tune job preparation - Creating role and policies requirements\n",
    "\n",
    "We will now prepare the necessary IAM role for the fine-tune job. This includes creating the policies required to run customization jobs with Amazon Bedrock.\n",
    "\n",
    "### Create Trust relationship\n",
    "This JSON object defines the trust relationship that allows the Bedrock service to assume a role that will give it the ability to interact with other required AWS services. The conditions set restrict the assumption of the role to a specific account ID and a specific component of the Bedrock service (model_customization_jobs).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21cd89-b456-45a0-9b5a-6c7891a52ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This JSON object defines the trust relationship that allows the bedrock service to assume a role that will give it the ability to talk to other required AWS services. The conditions set restrict the assumption of the role to a specfic account ID and a specific component of the bedrock service (model_customization_jobs)\n",
    "ROLE_DOC = f\"\"\"{{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {{\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            }},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {{\n",
    "                \"StringEquals\": {{\n",
    "                    \"aws:SourceAccount\": \"{account_id}\"\n",
    "                }},\n",
    "                \"ArnEquals\": {{\n",
    "                    \"aws:SourceArn\": \"arn:aws:bedrock:{region}:{account_id}:model-customization-job/*\"\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bfe6e-6329-499e-aa56-4b363584347f",
   "metadata": {},
   "source": [
    "### Create S3 access policy\n",
    "\n",
    "This JSON object defines the permissions of the role we want bedrock to assume to allow access to the S3 bucket that we created that will hold our fine-tuning datasets and allow certain bucket and object manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01110bb2-7844-488b-a2dd-36e82bccb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_POLICY_DOC = f\"\"\"{{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:AbortMultipartUpload\",\n",
    "                \"s3:DeleteObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:GetBucketAcl\",\n",
    "                \"s3:GetBucketNotification\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:PutBucketNotification\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{bucket}\",\n",
    "                \"arn:aws:s3:::{bucket}/*\"\n",
    "            ]\n",
    "        }}\n",
    "    ]\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde13dd-5681-4faf-9c94-bce11f40a367",
   "metadata": {},
   "source": [
    "### Create IAM role and attach policies\n",
    "\n",
    "Let's now create the IAM role with the created trust policy and attach the s3 policy to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face3f85-169e-4ba3-a714-f6e4c58d142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = name_from_base(f\"FineTuning-{prefix.split('/')[-1]}\")\n",
    "s3_bedrock_ft_access_policy = f\"{role_name}-policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc68b7-8c9d-4d8a-bc62-ecea1d343988",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = iam_client.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=ROLE_DOC,\n",
    "    Description=\"Role for Bedrock to access S3 for finetuning\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2752b9-9a91-477a-8942-09fbae063a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn = response[\"Role\"][\"Arn\"]\n",
    "response = iam_client.create_policy(\n",
    "    PolicyName=s3_bedrock_ft_access_policy,\n",
    "    PolicyDocument=ACCESS_POLICY_DOC,\n",
    ")\n",
    "policy_arn = response[\"Policy\"][\"Arn\"]\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=policy_arn,\n",
    ")\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d526c16-3c10-47f9-b6e8-afecb6442ad5",
   "metadata": {},
   "source": [
    "### Create a Customization Job\n",
    "\n",
    "Now that we have all the requirements in place, let's create the fine-tuning job with the Titan Image Generator model.\n",
    "\n",
    "To do so, we need to set the model **hyperparameters** for `stepCount`, `batchSize` and `learningRate` and provide the path to your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5a09e-08c8-44ae-a6d5-d4013e4ede7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_name =  f\"{prefix.split('/')[0]}-v0\"\n",
    "roleArn = role_arn\n",
    "jobName = name_from_base(model_name)\n",
    "customModelName = jobName\n",
    "hyperParameters = {\n",
    "        \"stepCount\": \"14000\",\n",
    "        \"batchSize\": \"64\",\n",
    "        \"learningRate\": \"0.000001\",\n",
    "    }\n",
    "trainingDataConfig = {\"s3Uri\": training_path}\n",
    "outputDataConfig = {\"s3Uri\": f\"s3://{bucket}/{prefix}\"}\n",
    "\n",
    "# Create job\n",
    "response_ft = bedrock.create_model_customization_job(\n",
    "    jobName=jobName,\n",
    "    customModelName=customModelName,\n",
    "    roleArn=roleArn,\n",
    "    baseModelIdentifier=model_id,\n",
    "    hyperParameters=hyperParameters,\n",
    "    trainingDataConfig=trainingDataConfig,\n",
    "    outputDataConfig=outputDataConfig\n",
    ")\n",
    "\n",
    "jobArn = response_ft.get('jobArn')\n",
    "print(jobArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18909c-37d7-4617-8e0c-e275082d8d0d",
   "metadata": {},
   "source": [
    "### Waiting until customization job is completed\n",
    "Once the customization job is finished, you can check your existing custom model(s) and retrieve the modelArn of your fine-tuned model.\n",
    "\n",
    "<div class=\\\"alert alert-block alert-warning\\\">\n",
    "    <b>Warning:</b> The model customization job can take hours to run. With 12000 steps, 0.000001 learning rate, 64 of batch size and x images, it takes around 4 hours to complete\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcf3b2-e636-4d32-b144-cbddff810362",
   "metadata": {},
   "source": [
    "### Set Job Name\n",
    "\n",
    "The code below allows you to check the status of an existing job.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>WARNING:</b> This job can take up to 12 hours to complete. Please be patient, you can always comeback and continue the subsequent steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642c9bb-edc2-4577-bfe4-2ad9f5d647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model customization status\n",
    "status = bedrock.list_model_customization_jobs(\n",
    "    nameContains=jobName\n",
    ")[\"modelCustomizationJobSummaries\"][0][\"status\"]\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333cf65f-b333-46cc-bf21-748b6b34921d",
   "metadata": {},
   "source": [
    "Once Complete, get the new `customModelARN` using the code below, or you can manually set the parameter by copying the `customModelARN` from the console. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19b1f3-dcc0-4441-9769-6a487b958f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_arn = bedrock.list_model_customization_jobs(\n",
    "    nameContains=jobName\n",
    ")[\"modelCustomizationJobSummaries\"][0][\"customModelArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321b895-3788-4caa-8a0e-72a2ee626a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_model_arn = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a1dfb-7a6d-40a8-b503-3ab2ea4c6994",
   "metadata": {},
   "source": [
    "## Host Fine-tuned Model With Provisioned Throughput (PT)\n",
    "\n",
    "You will need to create provisioned throughput to be able to evaluate the model performance. You can do so through the console or use the following api call.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>WARNING:</b> Creating provisioned throughput will take 30mins to complete.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87799b1-81dd-4029-86bf-adcab30133a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_name = name_from_base(model_name)\n",
    "\n",
    "# Create the provision throughput job and retrieve the provisioned model id\n",
    "provisioned_model_id = bedrock.create_provisioned_model_throughput(\n",
    "    modelUnits=1,\n",
    "    # create a name for your provisioned throughput model\n",
    "    provisionedModelName=custom_model_name, \n",
    "    modelId=custom_model_arn\n",
    ")['provisionedModelArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f942c-5e34-4305-bac3-7402a3837015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# check provisioned throughput job status\n",
    "import time\n",
    "status_provisioning = bedrock.get_provisioned_model_throughput(provisionedModelId = provisioned_model_id)['status'] \n",
    "while status_provisioning == 'Creating':\n",
    "    time.sleep(60)\n",
    "    status_provisioning = bedrock.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id)['status']\n",
    "    print(status_provisioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d998c5-3cb5-488c-a0fd-2aec17c847b7",
   "metadata": {},
   "source": [
    "### Set Provisioned Model ID\n",
    "\n",
    "Similar to the job name, if you're returning to this notebook after creating a provisioned throughput, you can set the provisioned model ID manually here. This allows you to use an existing provisioned model without waiting for a new one to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d998c5-3cb5-488c-a0fd-2aec17c847b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provisioned_model_id = \"<ENTER-YOUR-PT-ARN>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b209c-bfb2-43ab-bd3a-ee5422813a15",
   "metadata": {},
   "source": [
    "## Test Fine-tuned Model\n",
    "We will now run some model experiments using the bedrock-runtime client with the invoke_model function to invoke both fine-tuned and pre-trained models.\n",
    "\n",
    "To invoke the provisioned custom model, notice you will need to run the previous step (create provisioned throughput) before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f03dd4-9f26-4854-9f98-83f02abefd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "def decode_base64_image(img_b64):\n",
    "    return Image.open(io.BytesIO(base64.b64decode(img_b64)))\n",
    "    \n",
    "def generate_image(prompt,\n",
    "                   negative_prompt=\"text, ugly, blurry, distorted, low quality, pixelated, watermark, text, deformed\", \n",
    "                   num_of_images=3,\n",
    "                   seed=1):\n",
    "    \"\"\"\n",
    "    Generate an image using Amazon Nova Canvas.\n",
    "    \"\"\"\n",
    "\n",
    "    image_gen_config = {\n",
    "            \"numberOfImages\": num_of_images,\n",
    "            \"quality\": \"premium\",\n",
    "            \"width\": 1024,  # Maximum resolution 2048 x 2048\n",
    "            \"height\": 1024,  # 1:1 ratio\n",
    "            \"cfgScale\": 8.0,\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "\n",
    "    # Prepare the request body\n",
    "    request_body = {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,\n",
    "            \"negativeText\": negative_prompt,  # List things to avoid\n",
    "        },\n",
    "        \"imageGenerationConfig\": image_gen_config\n",
    "    } \n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=provisioned_model_id,\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    response_body = json.loads(response['body'].read())\n",
    "\n",
    "    if \"images\" in response_body:\n",
    "        # Extract the image\n",
    "        return [decode_base64_image(img) for img in response_body['images']]\n",
    "    else:\n",
    "        print(response_body)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf758f0-a3e7-4e66-b9be-fb8f4e80bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Mayu smiling with a mistic forest in the background\"\n",
    "# prompt = \"Close-up of Mayu gestures towards a cute, fluffy white baby llama with big curious eyes.\"\n",
    "# prompt = \"Mayu is sitting on the ground with fence of rope around her. She has a confused expression. A fluffy white baby llama prances near her. The background shows hills and sky.\"\n",
    "# prompt = \"Mayu stands in front of a wooden fence. A cute fluffy white baby llama stands triumphantly in the foreground. Small bags are scattered on the ground near the llama. A comical scene in the Peruvian Andes.\"\n",
    "# prompt = \"Mayu playing a flute. Beside her, a fluffy white baby llama with its big curious eyes focused on Mayu. The background showcases Andean mountains.\"\n",
    "# prompt = \"An Andean village scene with traditional buildings. In the center, Mayu stands confidently playing a wooden flute. Next to her, a cute white baby llama dances, carrying a small woven bag in its mouth\"\n",
    "# prompt = \"Mayu standing proudly at the entrance of a simple school building. Her face beams with a wide smile, expressing pride and accomplishment.\"\n",
    "# prompt = \"Mayu face shows a mix of nervousness and determination. Mommy kneels beside her, gently holder her. A landscape is visible in the background.\"\n",
    "# prompt = \"A steep cliff face with a long wooden ladder extending downwards. Halfway down the ladder is Mayu with a determined expression on her face. Mayu’s small hands grip the sides of the ladder tightly as she carefully places her feet on each rung. The surrounding environment shows a rugged, mountainous landscape.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1cf7d-0f0c-43ef-b9fb-a77686505d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "seed = random.randint(1, 858993459)\n",
    "print(f\"seed: {seed}\")\n",
    "\n",
    "images = generate_image(prompt=prompt, seed=seed)\n",
    "\n",
    "if images:\n",
    "    n = len(images)\n",
    "    cols = min(3, n)  # number of columns\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(cols * 5, rows * 5))\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787936e9-1920-4022-be8a-833efaa0efd8",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>WARNING:</b> After you are done, please remove provision throughput and fine-tuned model to avoid additional charges\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ef7eb-12b6-4c72-a20a-fdea985d92e7",
   "metadata": {},
   "source": [
    "Delete Provisioned Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ef7eb-12b6-4c72-a20a-fdea985d92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.delete_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99168f-b29d-49aa-9fd3-60be78f23d08",
   "metadata": {},
   "source": [
    "Delete Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99168f-b29d-49aa-9fd3-60be78f23d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.delete_custom_model(\n",
    "    modelIdentifier=custom_model_arn\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

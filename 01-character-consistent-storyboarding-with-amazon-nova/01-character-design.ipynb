{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this hands-on session, we'll explore how to use the Nova Canvas text-to-image capabilities to create consistent character designs for storyboards and visual development.\n",
    "\n",
    "## Use Case\n",
    "\n",
    "OctankStudio, a fictional animation studio, would like to leverage AI image generation to streamline their character design and storyboarding process. Specifically, they need to:\n",
    "\n",
    "1. Establish a consistent visual style and character design for the protagonist in their upcoming animated short film.\n",
    "2. Ensure the character maintains a cohesive look and feel across all the generated images.\n",
    "\n",
    "## Workshop Objectives\n",
    "\n",
    "By the end of this workshop, you will:\n",
    "\n",
    "1. Understand how to use text prompts with the Nova Canvas model to generate consistent character designs.\n",
    "2. Learn techniques for controlling the visual style, proportions, and other attributes of generated characters.\n",
    "3. Gain hands-on experience using the Amazon Bedrock API to create a library of character images for storyboarding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Prerequisites:</b> Please run the prerequiresites <b>00-prerequisites.ipynb</b> first before proceeding.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Text-To-Image\n",
    "\n",
    "The simplest way to use the model is to generate images based on a text description. In Nova Canvas, this mode of generation is identified with a `taskType` of \"TEXT_IMAGE\". In this notebook, you'll explore a few of the parameters supported by the \"TEXT_IMAGE\" task type.\n",
    "\n",
    "To begin, run the cell below to create an instance of the Bedrock Runtime client. We'll use this to call the model later.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<strong>⚠️ Important:</strong> Note that we configure the client to use a longer read timeout of 5 minutes. This is a best practice when working with Nova Canvas because, depending on the parameters you configure and the number of images you request, processing can take longer than the AWS SDK default timeout of 60 seconds.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import io\n",
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from PIL import Image\n",
    "from \"helpers/image_utils\" import save_image, plot_images, plot_images_for_comparison\n",
    "\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=Config(\n",
    "        read_timeout=5 * 60\n",
    "    ),  # IMPORTANT: Increase the read timeout to 5 minutes to support longer operations.\n",
    ")\n",
    "image_generation_model_id = \"amazon.nova-canvas-v1:0\"\n",
    "output_dir = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - Creating images using text prompts\n",
    "\n",
    "In this section, you'll explore prompt engineering techniques for designing a character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a helper function to generate images with different seed values using the Amazon Bedrock `invoke_model` API.  In the following exercises, we will use this function to explore how changing the `seed` and `cfgScale` value API parameters changes the images generated by Nova Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(text, seed_values = [57], cfg_scale_values = [6.5]):\n",
    "    \"\"\"Generate images using the Amazon Nova Canvas text-to-image model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text prompt to use for image generation.\n",
    "        cfgScale (float, optional): The configuration scale to use for image generation. Controls how closely the generated images match the prompt. Defaults to 6.5.\n",
    "        seed_values list of int: The random seed to use for image generation. \n",
    "\n",
    "    Returns:\n",
    "        list: A list of generated images as PIL.Image objects.\n",
    "    \"\"\"\n",
    "    generated_images = []\n",
    "\n",
    "    # Generate image using only a text prompt.\n",
    "    for index, seed in enumerate(seed_values):\n",
    "        for index, cfg_scale in enumerate(cfg_scale_values):\n",
    "            body = json.dumps(\n",
    "                {\n",
    "                    \"taskType\": \"TEXT_IMAGE\",\n",
    "                    \"textToImageParams\": {\"text\": text},\n",
    "                    \"imageGenerationConfig\": {\n",
    "                        \"numberOfImages\": 1,  # Number of images to generate, up to 5\n",
    "                        \"width\": 1024,\n",
    "                        \"height\": 1024,\n",
    "                        \"cfgScale\": cfg_scale,  # How closely the prompt will be followed\n",
    "                        \"seed\": seed,  # Any number from 0 through 858,993,459\n",
    "                        \"quality\": \"premium\",  # Quality of either \"standard\" or \"premium\"\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "    \n",
    "            print(f\"Generating image {index + 1} of {len(seed_values)}...\")\n",
    "        \n",
    "            response = bedrock_runtime_client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=image_generation_model_id,\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\",\n",
    "            )\n",
    "        \n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "        \n",
    "            base64_images = response_body.get(\"images\")\n",
    "            image_path = f\"{output_dir}/01-text-to-image_seed-{seed}-cfg_scale-{cfg_scale}.png\"\n",
    "            save_image(base64_images[0], image_path)\n",
    "        \n",
    "            print(f\"Saved to {image_path}\")\n",
    "        \n",
    "            generated_img = [\n",
    "                Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "                for base64_image in base64_images\n",
    "            ]\n",
    "            generated_images.append(generated_img[0])\n",
    "\n",
    "    return generated_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompting for image generation models differs from prompting for large language models (LLMs). Image generation models do not have the ability to reason or interpret explicit commands. Therefore, it's best to phrase your prompt as if it were an image caption rather than a command or conversation. You might want to include details about the subject, action, environment, lighting, style, and camera position.\n",
    "\n",
    "Let's start developing our character by creating a simple description of Mayu:\n",
    "\n",
    "> A 7 year old peruvian girl with dark hair in two low braids wearing a school uniform.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_description = \"A 7 year old peruvian girl with dark hair in two low braids wearing a school uniform.\"\n",
    "text = f\"{character_description}\"\n",
    "seed_values = [57]  # Any number from 0 through 858,993,459\n",
    "generated_images = generate_images(text, seed_values)\n",
    "\n",
    "# Plot comparison images\n",
    "plot_images_for_comparison(\n",
    "    generated_images=generated_images,\n",
    "    labels=seed_values,\n",
    "    prompt=text,\n",
    "    comparison_mode=True,\n",
    "    title_prefix=\"Seed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Adding visual style to a character\n",
    "\n",
    "An effective prompt often includes short descriptions of the subject and the environment.  Optionally, you can add information to control the composition and visual style for images.  \n",
    "\n",
    "For storyboarding, the composition elements such as camera position, pose, and lighting will vary from scene to scene, but the style will be one of the unifying elements that can help create consistency across scenes.\n",
    "\n",
    "In the section below, you'll define several visual styles.  To adhere to prompt engineering best practice of keeping the most important details at the beginning of a prompt, the style information is separated into two parts.  The `description` is the main visual style class and medium.  The `details` is more supporting details about the characteristics of the style.  When we build our prompts the description will go at the beginning and the `details` will be placed at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\n",
    "    {\n",
    "        \"name\": \"graphic-novel\",\n",
    "        \"description\": \"A graphic novel style illustation of\",\n",
    "        \"details\": \"Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sketch\",\n",
    "        \"description\": \"A simple black and white line sketch of\",\n",
    "        \"details\": \"Rough, sketch-like lines create a storyboard aesthetic. High contrast. No color\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"digital-illustration\",\n",
    "        \"description\": \"A 3D digital drawing of\",\n",
    "        \"details\": \"High contrast. Rounded character design. Smooth rendering. Soft texture. Luminous lighting\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create enum for meaningful index names\n",
    "GRAPHIC_NOVEL = 0\n",
    "SKETCH = 1\n",
    "DIGITAL_ILLUSTRATION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate some images of Mayu using the different styles by constructing a prompt with the following elements:\n",
    "\n",
    "> style description + character description + style details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_description = \"A 7 year old peruvian girl with dark hair in two low braids wearing a school uniform.\"\n",
    "\n",
    "generated_images = []\n",
    "for style in styles:\n",
    "\n",
    "    text = f\"{style[\"description\"]} {character_description} {style[\"details\"]}\"\n",
    "    seed_values = [57]  # Any number from 0 through 858,993,459\n",
    "    generated_images.extend(generate_images(text, seed_values))\n",
    "\n",
    "labels = [style[\"name\"] for style in styles]\n",
    "\n",
    "# Plot comparison images\n",
    "plot_images_for_comparison(\n",
    "    generated_images=generated_images,\n",
    "    labels=labels,\n",
    "    prompt=text,\n",
    "    comparison_mode=True,\n",
    "    title_prefix=\"Style: \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Developing character variations using seeds\n",
    "\n",
    "When the output you get from a prompt is close to what you want but not quite perfect, try the following techniques one at a time in turn to refine your result:\n",
    "\n",
    "- Using a consistent seed value, make small changes to your prompt or negative prompt and re-run the prompt. This allows you to better understand how your prompt wording affects the output, allowing you to iteratively improve your results in a controlled way.\n",
    "\n",
    "- Once the prompt has been refined to your liking, generate more variations using the same prompt but a different seed value. It is often useful to generate multiple variations of an image by running the sample prompt with different seeds in order to find that perfect output image.\n",
    "\n",
    "We want to generate a few designs that we can choose from. The `seed` parameter can help with this.\n",
    "\n",
    "The `seed` parameter provides a way to introduce randomness into the output for a given text prompt. Using different seed values while leaving the text prompt unchanged will produce images that all adhere to the prompt but vary in their visual appearance. For this reason, `seed` can be an useful way to produce many variations based on a single text prompt.\n",
    "\n",
    "Let's see how different seed values can impact the results. Run the cells below. The generated images will be saved to the \"output\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main input parameters.\n",
    "character_description = \"A 7 year old peruvian girl with dark hair in two low braids wearing a school uniform.\"\n",
    "style = styles[GRAPHIC_NOVEL]\n",
    "text = f\"{style[\"description\"]} {character_description} {style[\"details\"]}\"\n",
    "seed_values = [1, 20, 57, 139, 12222]  # Any number from 0 through 858,993,459\n",
    "generated_images = generate_images(text, seed_values)\n",
    "\n",
    "# Plot comparison images\n",
    "plot_images_for_comparison(\n",
    "    generated_images=generated_images,\n",
    "    labels=seed_values,\n",
    "    prompt=text,\n",
    "    comparison_mode=True,\n",
    "    title_prefix=\"Seed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>💡 Bonus Activity:</strong> Try different seeds to generate a different set of variations. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>💡 Bonus Activity:</strong> Try different styles to generate a different set of variations. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Developing character variations using the \"cfgScale\" parameter\n",
    "\n",
    "The `cfgScale` parameter controls how closely your prompt will be followed. In this example, we are going to generate images using different values for `cfgScale` to see their effect.\n",
    "\n",
    "`cfgScale` may be set to min 1.1 up to a max of 10. Lower values give the model more freedom to interpret your prompt loosely. Higher values are more faithful to your prompt, but setting the value too high can result in over-emphasis of some things mentioned in your prompt. The default is 6.5 and is a good starting point.\n",
    "\n",
    "Run the cells below. The generated images will be saved to the \"output\" folder. Note how a value of 10 (the maximum) results in over-emphasis of the \"skate shop\" part of the prompt, adding wheels to everything!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the main input parameters.\n",
    "character_description = \"A 7 year old peruvian girl with dark hair in two low braids wearing a school uniform.\"\n",
    "style = styles[GRAPHIC_NOVEL]\n",
    "text = f\"{style[\"description\"]} {character_description} {style[\"details\"]}\"\n",
    "cfg_scale_values = [1.1, 3.5, 6.5, 8.0, 10]\n",
    "seed_values = [57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generated_images = generate_images(text, seed_values, cfg_scale_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison images\n",
    "plot_images_for_comparison(\n",
    "    generated_images=generated_images,\n",
    "    labels=cfg_scale_values,\n",
    "    prompt=text,\n",
    "    comparison_mode=True,\n",
    "    title_prefix=f\"Seed = {seed_values[0]}, Strength\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Using our character in a story\n",
    "\n",
    "Now that you have a feel for some of the tools that can be used to engineer prompts with consistent images, let's try featuring the characters a few different scenes.  In order to achieve consistency, we will need to include consistent settings for the style, seed, cfgScale and character description in the Nova Canvas prompt for each scene. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [\n",
    "    \"ridng a bike on a mountain pass\",\n",
    "    \"walking on a path through tall grass in the Andes\",\n",
    "    \"eating ice cream at the beach\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main input parameters.\n",
    "character_description = \"A 7 year old peruvian girl with dark hair in two low braids wearing a school uniform.\"\n",
    "style = styles[GRAPHIC_NOVEL]\n",
    "cfg_scale_values = [6.5]\n",
    "seed_values = [57]\n",
    "\n",
    "for scene in scenes:\n",
    "    text = f\"{style[\"description\"]} {character_description} {scene} {style[\"details\"]}\"\n",
    "    generated_images = generate_images(text, seed_values, cfg_scale_values)\n",
    "\n",
    "    # Plot comparison images\n",
    "    plot_images_for_comparison(\n",
    "        generated_images=generated_images,\n",
    "        labels=[f\"Seed: {seed}, Cfg_scale: {cfg}\" for seed in seed_values for cfg in cfg_scale_values],\n",
    "        prompt=text,\n",
    "        comparison_mode=True,\n",
    "        title_prefix=f\"Seed = {seed_values[0]}, Strength\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>💡 Bonus Activity:</strong> Try different styles, seeds and cfg_scale to generate a different set of variations. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Away\n",
    "\n",
    "Text-to-image generation is a powerful feature that empowers users to create visual content from textual descriptions. By simply writing descriptive text prompts, individuals can generate unique and diverse images that match their vision. This innovative tool has wide-ranging applications, from conceptual art and storyboarding to rapid prototyping and visual brainstorming. Whether you're an artist seeking inspiration, a marketer creating promotional materials, or a game developer designing characters, the text-to-image feature of Nova Canvas offers an efficient and accessible way to bring ideas to life visually.\n",
    "\n",
    "Continue to the next section to learn about creating an end-to-end prompt flow for creating image and video storyboards using a consistent character design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
